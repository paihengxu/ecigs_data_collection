try:
    from ipdb import set_trace
except ImportError:
    from pdb import set_trace
import logging
import os
import pandas as pd
from falconet import annotators 
from falconet.utils import fatal_exception
from falconet.utils import ensure_folder
from falconet.utils import get_hour_str_from_date_with_utc_offset
from falconet.utils import get_day_from_date
from falconet.utils import get_month_from_date
from falconet import settings


class AnnotationCounter:
    """
        Counts and aggregates labels generated by a pipeline
    """
    def __init__(self, labels, aggregations, counter_period="day", 
                 time_zone="UTC"):
        self.labels = labels
        self.aggregations = aggregations
        self.counter_period = counter_period
        self.time_zone = time_zone
        self.data = pd.DataFrame(columns=[settings.TIMESTAMP]+labels)
        
    def count(self, post):
        if self.counter_period == "day":
            period = get_day_from_date(post.timestamp(), self.time_zone)
        elif self.counter_period == "hour":
            period = get_hour_str_from_date_with_utc_offset(post.timestamp(), self.time_zone)
        elif self.counter_period == "month":
            period = get_month_from_date(post.timestamp(), self.time_zone)
        else:
            raise NotImplementedError("counter period: {}".format(self.counter_period))
        datum = ["UNK"]*len(self.data.columns)
        datum[0] = period
        for i, label in enumerate(self.labels):
            try:
                if label == "lang":
                    value = post.annotations["langid"]["lang"]
                elif 'location' in label:
                    if '-' in label:
                        location_str, loc = label.split('-')
                        assert location_str == 'location'
                        assert loc in {'country', 'state', 'county', 'city'}
                    else:
                        # default is state
                        loc = 'state'
                    value = post.annotations["location"][loc] if post.annotations["location"] else 'UNK'
                else:
                    value = post.annotations[label]
            except KeyError:
                value = "UNK"
            # first entry contains the timestamp
            datum[i+1] = value
        self.data.loc[len(self.data)] = datum
        
    def flush(self, output_file, write_mode="a"):
        if len(self.data) > 0:     
            raw_counts = self.data.sort_values(by=settings.TIMESTAMP)
            ensure_folder(output_file)
            # if file does not exist, add header
            header = not os.path.isfile(output_file)
            fname, fext = os.path.splitext(output_file)
            for agg in self.aggregations:
                if agg.lower() != "none":    
                    # get aggregation fields and aggregate data           
                    agg_fields = agg.split(",")              
                    counts = raw_counts.groupby(agg_fields).size()
                    counts.to_csv(path_or_buf=fname+"_"+"_".join(agg_fields)+fext, header=header,
                                  mode=write_mode)                    
                else:                
                    raw_counts.to_csv(path_or_buf=output_file, header=header, mode=write_mode)
        else:
            print("Nothing to flush")


class Pipeline:
    """
        Implements a pipeline specified as json config file
    """
    def __init__(self, config, counter_output=None):
        self.config = config
        self.name = config["name"]        
        self._pipeline = []
        self.__classifiers = []
        self.__scorers = []
        self.counter_output = counter_output
        self.build_pipeline(config)
        if counter_output:
            self.get_counter(config)
        
    def get_counter(self, config):
        if "counter" in config: 
            try:             
                labels = config["counter"]["labels"]
                try:
                    aggregations = config["counter"]["aggregations"]
                except KeyError:
                    aggregations = "none"

                try:
                    period = config["counter"]["period"]
                except KeyError:
                    period = "day"

                self.counter = AnnotationCounter(labels, aggregations=aggregations,
                                                 counter_period=period)
            except KeyError as e:                
                print("[ERROR: could not create counter > {}]".format(str(e)))

    def build_pipeline(self, config):
        # load models
        for m in config["pipeline"]:
            # models defined as a string use default args
            model = None
            if isinstance(m, str):
                model_name = m.lower()
                if model_name == "carmen":
                    model = annotators.CarmenLocationAnnotator()
                elif model_name == "tokenizer":
                    model = annotators.TokenizeAnnotator()
                elif model_name == "langid":
                    model = annotators.LangidAnnotator()
                elif model_name == "genderperformr":
                    model = annotators.GenderPerformrAnnotator()
                elif model_name == 'shareslink':
                    model = annotators.SharesLinkAnnotator()
                elif model_name == 'twitter-verified-user':
                    model = annotators.TwitterVerifiedUserAnnotator()
                elif model_name == "liwc":
                    model = annotators.LiwcAnnotator()
                else:
                    raise NotImplementedError("model {}".format(model_name))
            # models defined as a dict can pass custom args
            elif isinstance(m, dict):
                model_name = m["model"].lower()
                args = m["args"]
                if model_name == "keywords":
                    if not os.path.exists(args['filename']):
                        args["filename"] = settings.RESOURCES_DISEASE_KEYWORDS + args['filename']
                    model = annotators.KeywordAnnotator(**args)
                elif model_name == "carmen":
                    model = annotators.CarmenLocationAnnotator(**args)
                elif model_name == "langid":
                    model = annotators.LangidAnnotator(**args)
                elif model_name == "subreddit":
                    if not os.path.exists(args['kw_path']):
                        args["kw_path"] = settings.RESOURCES_SUBREDDITS + args['kw_path']
                    model = annotators.SubredditAnnotator(**args)
                elif model_name == "classifier":
                    model = self.__get_classifiers_by_filename_attributes(**args)
                elif model_name == "scorer":
                    model = self.__get_scorers_by_filename_attributes(**args)
                elif model_name == "demographer":
                    model = annotators.DemographerAnnotator(**args)
                elif model_name == "m3inference":
                    model = annotators.M3InferenceAnnotator(**args)
                else:
                    raise NotImplementedError("model w/custom args {}".format(model_name))
            else:
                raise RuntimeError("Invalid file format")
            if model:
                self._pipeline.append(model)
        
    def run(self, p):
        # annotations
        for annotator in self._pipeline:            
            annotator.annotate(p)
            # leave early?
            if 'skip_message' in p.metadata:
                return p
        try:
            self.counter.count(p)
        except AttributeError:
            # counter does not exist
            pass

        return p
    
    def flush_counts(self):
        try:
            self.counter.flush(self.counter_output)
        except AttributeError:
            # counter does not exist            
            print("[No Counter]")

    def __get_classifiers_by_filename_attributes(self, **train_args):
        """providing multiple trainargs mean AND, not OR"""
        # e.g. 'prefix' or 'depvar'
        if not self.__classifiers:
            self.__classifiers = load_models(settings.MODELS_PATH, "classifier")
        for x in self.__classifiers:
            keep = True
            for k, v in train_args.items():
                if x._model._trainArgs[k] != v:
                    keep = False
                    break
            if keep:
                return x
        return None
    
    def __get_scorers_by_filename_attributes(self, **train_args):
        """providing multiple trainargs mean AND, not OR"""
        # e.g. 'prefix' or 'depvar'
        if not self.__scorers:
            assert "models_path" in self.config, "missing [models_path] parameter"
            self.__scorers = load_models(self.config["models_path"],"scorer")
        assert self.__scorers, "No models found @ {}".format(self.config["models_path"])
        for x in self.__scorers:
            keep = True
            for k, v in train_args.items():
                if x._model._trainArgs[k] != v:
                    keep = False
                    break
            if keep:
                return x
        return None


# TODO:review this method
def load_models(models_dir, model_type):
    assert model_type in ["classifier", "scorer"]
    print("[loading models @ {}]".format(models_dir))
    classifier_paths = [os.path.join(models_dir, p) for p in os.listdir(models_dir) or 
                        fatal_exception("model dir empty: %s" % models_dir, FileNotFoundError, logging) 
                        if p.endswith('.pickle')]
    
    print("[models: {}]".format("; ".join(classifier_paths)))
    # annotate most likely label
    if model_type == "scorer":
        all_models = [annotators.ScoreAnnotator(p) for p in classifier_paths or 
                      fatal_exception("no classifier files in: %s" % models_dir, FileNotFoundError, logging)]
    else:         
        all_models = [annotators.ClassifierAnnotator(p) for p in classifier_paths or 
                      fatal_exception("no classifier files in: %s" % models_dir, FileNotFoundError, logging)]
    
    return all_models
